---
title: "Week 3 Slides"
subtitle: "Data Cleaning, Organizing, Describing, and Communicating"
author: "Andrew Katz"
institute: "Department of Engineering Education <br><br> Virginia Tech"
date: "2021-02-02"
output:
  xaringan::moon_reader:
    lib_dir: libs
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
---
```{r setup-chunk, echo=FALSE}
library(tidyverse)


xaringanExtra::use_panelset()


```




.center[

# Week 3 Announcements

]

--
### Don't forget about post-class reflections

--

### The weekly writing assignments (i.e., reflections and class prep) do not need to follow the provided templates

--
### I _do_ try to respond to comments or questions that you leave in your Google Docs

--

### I will try to post slides before class, but we will be adding to them as we go along. The .rmd and .pdf files will be available at the course GitHub repo.


---

.center[
# More Week 3 Announcements
]

### A note about course material organization
* It sounds like the course organization is not a hindrance for anyone so far. If you do find yourself
having issues finding things, **_please let me know!_**

--

### A note about the pace of the course
* There is a lot of material that we cover in the first few weeks
* The pace will not stay this way - we will slow down
* Try to think of this as a steep ramp-up period for introducing things
that we will iteratively practice



---

.center[
# Week 3 Reading Assignment
]

.pull-left[
## DSUR - Chapter 4:  
Exploring Data with Graphs
]

.pull-right[
## R4DS - Sections 9 - 21

]

<br>

---


# Today's Plan

### Review Chapter 2 of DSUR

--

### Review Chapter 4 of DSUR

--

### Start working in R


---


---

.center[

# General Philosophy



.middle[

![](stats_prob_cycle.png)

]


*We will revisit this image/idea throughout the semester 


]





---

.center[
# Hypothesis Testing
]

* Null hypothesis
* Alternative hypothesis


---
class: inverse, middle, center

# Chapter Two

Everything You Ever Wanted to Know About Statistics




---

.center[
# Populations and Samples
]

---

# Statistical Models

### Linear models

$y_i = \beta_0 + \beta_1 * X_{1i} + \beta_2*X_{2i} + \cdots + e_i$



--

* Here, $y$ is the outcome variable, $X_1$ and $X_2$ are predictors, and $e_i$ is an error term to account for the error between the estimate of the model and the true value of the outcome variable observed in the data.

--

* Note that the term "linear model" here refers to the additivity of the terms and has nothing to do with the power that the predictors are raised to.

--

* The following is also a linear model:
$y_i = \beta_0 + \beta_1 * X_{1i}^2 + \beta_2*X_{2i}^3 + \cdots + e_i$





---
.center[
# Going Beyond the Data
]

### Standard error
* The terminology around this can be a little confusing. We will try a simulation in class to see if we can gain some intuition.
**Switch to simulation**

--


### Confidence intervals
* Be careful with the language about what confidence intervals can and cannot tell us


---

# Using Statistical Models to Test RQs
(A bit of philosophy)

1. Generate research question through initial observation
2. Generate a theory to explain your initial observation
3. Generate hypotheses - break theory into set of testable predictions
4. Collect data to test theory
5. Analyze the data - fit a statistical model


---

.center[
# Test Statistics


$test = \frac{\text{variance explained by model}}{\text{variance not explained by model}}$
]


* These test statistics can follow several common distributions such as a $t$ distribution, $F$ distribution, or $\chi^2$ distribution

--

* From a _frequentist_ perspective, these test statistics are meaningful because they can produce $p$ values

--

* A $p$ value tells you the probability of seeing a test statistic as extreme or more extreme under the null hypothesis


---

.center[
# Statistical Significance vs Practical Significance
]

* It is important to recognize that these two are different things

--

* Statistical difference refers to whether a p-value is below a certain threshold (usually 0.05)

--

* Practical significance tells us whether that difference is actually meaningful (i.e., the effect size)

---
.center[
# Type I and Type II Errors
]

.pull-left[


* Type I error is also known as a false positive


* Type I error involves finding a significant result when there actually is not


* $\alpha$-level refers to type I errors and is usually set at 0.05 (or 5%)

]

--

.pull-right[
* Type II error is also known as a false negative


* Type II error involves _not_ finding a significant result when there acutally _is_


* $\beta$-level refers to type II errors and is usually set at 0.8 (or 80%)
]


---

# General steps to remember

Do not bother to memorize these right now. Just note that this will be our general procedure in a few weeks.

* Identify a research question

* Identify how to collect data

* What are our hypotheses?

* What does statistical signifance mean here?

* What does practical significance mean here?


---

.center[

# Chapter Two Vocabulary

]

.pull-left[

$\alpha$-level <br>
$\beta$-level <br>
Central limit theorem <br>
Confidence interval <br>
Degrees of freedom <br>
Deviance <br>
Effect size <br>
Fit <br>
Linear model <br>
Meta-analysis <br>
One-tailed test <br>
Population <br>
Power <br>



]



.pull-right[

Sample <br>
Sampling distribution <br>
Sampling variation <br>
Standard deviation <br>
Standard error <br>
Standard error of the mean (SE) <br>
Sum of squared errors (SSE) <br>
Test statistic <br>
Two-tailed test <br>
Type I error <br>
Type II error <br>
Variance

]


---





class: center, inverse, middle

# Chapter Four 

Exploring Data with Graphs





---

.center[

# General Philosophy

.middle[

![Tidy-modeling](https://d33wubrfki0l68.cloudfront.net/795c039ba2520455d833b4034befc8cf360a70ba/558a5/diagrams/data-science-explore.png)

]

]









---

.center[
# Let's switch to working in R for the remainder of class

We will start with a few slides and then transition to working
in RStudio to practice a few common functions used for reading
in data, filtering, transforming, and visualizing data

]


---

.panelset[

.panel[.panel-name[R Code]
```{r example-hist, fig.show='hide', echo = TRUE}
num <- 50
mu <- 5
stdev <- 2

x <- rnorm(n = num, mean = mu, sd = stdev)
hist(x)


```

]

.panel[.panel-name[Plot]

```{r ref.label = 'example-hist', echo = FALSE}


```
]


.panel[.panel-name[ggplot Code]

```{r ggplot-hist, fig.show = 'hide', warning = FALSE, message = FALSE, echo = TRUE}
num <- 50
mu <- 5
stdev <- 2

x_vec <- rnorm(n = num, mean = mu, sd = stdev)
x_df <- tibble(x_col = x_vec)

ggplot(data = x_df, mapping = aes(x = x)) +
  geom_histogram()

```


]

.panel[.panel-name[ggplot Plot]

```{r ref.label = 'ggplot-hist', echo = FALSE}


```

]

.panel[.panel-name[ggplot Density]

```{r echo = FALSE}

num_big <- 5000
mu <- 5
stdev <- 2

x_vec_big <- rnorm(n = num_big, mean = mu, sd = stdev)
x_df_big <- tibble(x_col = x_vec_big)



ggplot(data = x_df_big, mapping = aes(x = x_col)) +
  geom_density()


```

]


]




---

# Discrete Predictor, Continuous Outcome

.center[
Boxplots
]

.panelset[


.panel[.panel-name[Code]

```{r boxplot-example, fig.show = 'hide', echo = TRUE}
group_size <- 20
chem_e_scores <- rnorm(n = group_size, mean = 85, sd = 4)
chem_scores <- rnorm(n = group_size, mean = 78, sd = 6)


data_df <- tibble(
  discipline = rep(c("ChemE", "Chemistry"), each = group_size),
  score = c(chem_e_scores, chem_scores)
)

data_df %>% 
  ggplot(aes(x = discipline, y = score)) +
  geom_boxplot()

```

]


.panel[.panel-name[Plot]

```{r ref.label = 'boxplot-example', echo = FALSE, out.width = '400px'}


```

]

.panel[.panel-name[Boxplot + Dots]
.pull-left[
```{r box-and-dot-plot, fig.show = 'hide', echo = TRUE}

data_df %>% 
  ggplot(aes(x = score, y = discipline)) +
  geom_boxplot() +
  geom_jitter()

```
]

.pull-right[

```{r ref.label = 'box-and-dot-plot', echo = FALSE}

```

]

]

]



]








